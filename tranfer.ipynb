{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtr, ytr), (xte, yte) = mnist.load_data()\n",
    "xtr = xtr.reshape(-1,28,28,1).astype(\"float32\")/255.0\n",
    "xte = xte.reshape(-1,28,28,1).astype(\"float32\")/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_start = keras.Sequential()\n",
    "model_start.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1),name='layer1'))\n",
    "model_start.add(layers.MaxPooling2D((2, 2),name='layer2'))\n",
    "model_start.add(layers.Conv2D(64, (3, 3), activation='relu',name='layer3'))\n",
    "model_start.add(layers.MaxPooling2D((2, 2),name='layer4'))\n",
    "model_start.add(layers.Conv2D(64, (3, 3), activation='relu',name='layer5'))\n",
    "model_start.add(layers.Flatten(name='layer6'))\n",
    "model_start.add(layers.Dense(64, activation='relu',name='layer7'))\n",
    "model_start.add(layers.Dense(10, activation='softmax', name='fin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./save/pretrain.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback Earlystopping (cb) :\n",
    "### avoid overfitting during trainning\n",
    "## Callback ModelCheck (ck) : \n",
    "### monitoring training weight and save best weight or last weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = tf.keras.callbacks.EarlyStopping(monitor='accuracy', mode='auto', restore_best_weights=True)\n",
    "ck = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='accuracy', verbose=0, save_best_only=True,mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "layer2 (MaxPooling2D)        (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "layer3 (Conv2D)              (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "layer4 (MaxPooling2D)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "layer5 (Conv2D)              (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "layer6 (Flatten)             (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "layer7 (Dense)               (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "fin (Dense)                  (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_start.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.0494 - accuracy: 0.9849\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0327 - accuracy: 0.9897\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0246 - accuracy: 0.9925\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0193 - accuracy: 0.9940\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0168 - accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x243c6a05970>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_start.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "model_start.fit(xtr, ytr, epochs=5, callbacks=[ck])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.0293 - accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.029279153794050217, 0.9922000169754028]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_start.evaluate(xte,yte, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion 1\n",
    "### [1] Basic model, train time = 197.0s,\n",
    "###     8 layers, 93,322 parameters\n",
    "###     0.9922 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------\n",
    "# Pre_train model\n",
    "\n",
    "## [1] models.load_model :\n",
    "### ready to use by calling saved weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer-learning workflow\n",
    "\n",
    "1. instantiate a base model and load pre-trained weights into it.\n",
    "2. Freeze all layers in the base model by setting <font color='red'>\"trainable = False.\"</font>\n",
    "3. Create a new model on top of the output of one (or several) layers from the base model.\n",
    "4. Train your new model on your new dataset.\n",
    "\n",
    "Alternative, lightweight workflow\n",
    "\n",
    "1. Instantiate a base model and load pre-trained weights into it.\n",
    "2. Run your new dataset through it and record the output of one (or several) layers 3. from the base model. This is called feature extraction.\n",
    "4. Use that output as input data for a new, smaller model.\n",
    "\n",
    "ref : https://keras.io/guides/transfer_learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze layesrs = NO CHANGE during training\n",
    "It is important to make a freezing the layers from the pre-trained model for avoiding the weights in selected layers to be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./save/pretrain.h5\")\n",
    "#[print(i.trainable) for i in model.layers]\n",
    "model.trainable = False\n",
    "\n",
    "for layer in model.layers:\n",
    "    assert layer.trainable ==False\n",
    "    layer.trainable = False\n",
    "#print(\"\\n\")\n",
    "#[print(i.trainable) for i in model.layers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning :\n",
    "It is about leveraging feature representation from a pre-trained model. From trained massive datasets, pre-trained model can be reused in other ways to predict new features. Moreover, it is useful to small training dataset because of using the weight from the pre-trained models to initialize the weights of the new model.\n",
    "\n",
    "## Fine-tuning :\n",
    "It is an optional step in tranfer learning such as a goal for improving the performance of the model with using pre_training weights and low learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_inputs = model.layers[0].input\n",
    "base_outputs = model.layers[-2].output\n",
    "final_outputs = layers.Dense(10)(base_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1_input (InputLayer)    [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "layer1 (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "layer2 (MaxPooling2D)        (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "layer3 (Conv2D)              (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "layer4 (MaxPooling2D)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "layer5 (Conv2D)              (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "layer6 (Flatten)             (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "layer7 (Dense)               (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 650\n",
      "Non-trainable params: 92,672\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "new_model = keras.Model(inputs=base_inputs, outputs=final_outputs)\n",
    "print(new_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = [\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 - 8s - loss: 0.1404 - accuracy: 0.9637\n",
      "Epoch 2/5\n",
      "1875/1875 - 8s - loss: 0.0124 - accuracy: 0.9969\n",
      "Epoch 3/5\n",
      "1875/1875 - 8s - loss: 0.0086 - accuracy: 0.9976\n",
      "Epoch 4/5\n",
      "1875/1875 - 8s - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 5/5\n",
      "1875/1875 - 8s - loss: 0.0060 - accuracy: 0.9982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x243c6c759d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Duration time after trainable = False \n",
    "new_model.fit(xtr,ytr,batch_size=32, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion 2\n",
    "### [2] pre_train model, train time = 40.7s,\n",
    "###     8 layers, 650 parameters (non-train 92,672)\n",
    "###     0.9982 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Duration time before trainable = False \n",
    "# new_model.fit(xtr,ytr,batch_size=32, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal(shape=(5,299,299,3))\n",
    "y = tf.constant([0,1,2,3,4])\n",
    "model_pre = keras.applications.InceptionV3(include_top=True)\n",
    "#print(model_pre.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_inputs = model_pre.layers[0].input\n",
    "base_outputs = model_pre.layers[-2].output\n",
    "final_outputs = layers.Dense(5)(base_outputs)\n",
    "new_model_pre = keras.Model(inputs=base_inputs, outputs=final_outputs)\n",
    "\n",
    "new_model_pre.compile(\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = [\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 - 9s - loss: 1.7041 - accuracy: 0.2000\n",
      "Epoch 2/5\n",
      "1/1 - 3s - loss: 0.1549 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "1/1 - 3s - loss: 5.3299e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "1/1 - 3s - loss: 1.9646e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "1/1 - 2s - loss: 1.0395e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24324415f70>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_pre.fit(x,y, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 - 5s - loss: 1.8779 - accuracy: 0.2000\n",
      "Epoch 2/5\n",
      "1/1 - 0s - loss: 1.6916 - accuracy: 0.2000\n",
      "Epoch 3/5\n",
      "1/1 - 0s - loss: 1.5723 - accuracy: 0.4000\n",
      "Epoch 4/5\n",
      "1/1 - 0s - loss: 1.4636 - accuracy: 0.4000\n",
      "Epoch 5/5\n",
      "1/1 - 0s - loss: 1.3349 - accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24324c878b0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal(shape=(5,299,299,3))\n",
    "y = tf.constant([0,1,2,3,4])\n",
    "url = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\n",
    "base_model = hub.KerasLayer(url, input_shape=(299,299,3))\n",
    "base_model.trainable = False\n",
    "model_news = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(5),\n",
    "])\n",
    "model_news.compile(\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = [\"accuracy\"],\n",
    ")\n",
    "model_news.fit(x,y, epochs=5, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc434e5b572f89136b29295e397389425a441df70a31cdf79b084fd634ffb388"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('qml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
